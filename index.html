<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>Probabilidad y Estad√≠stica </title>
</head>
<body>
 <a href="app.dataquest.io/profile/230110118">Perfil DATAQUEST</a>


    <h1>1 Estad√≠stica descriptiva</h1>
   
    <h2>1.1 Conceptos basicos de estadistica</h2>
    <h3>Definici√≥n</h3>
    <p>La estad√≠stica es una ciencia que se encarga de la recolecci√≥n, organizaci√≥n, an√°lisis e interpretaci√≥n de datos para obtener conclusiones sobre un conjunto de individuos o eventos. Se utiliza en diversos campos como la investigaci√≥n cient√≠fica, la econom√≠a, la medicina, la ingenier√≠a y las ciencias sociales.</p>
    <h3>Teor√≠a de decisi√≥n</h3>
    <p> La teor√≠a de decisi√≥n es una rama de la estad√≠stica que se enfoca en tomar decisiones √≥ptimas frente a la incertidumbre. Se utiliza para evaluar diferentes opciones y elegir la que tiene la mayor probabilidad de √©xito, considerando los riesgos y beneficios asociados a cada una.</p>
    <h3>Poblaci√≥n</h3>
    <p> La poblaci√≥n es el conjunto completo de individuos o eventos que queremos estudiar. Es un grupo finito o infinito que tiene caracter√≠sticas comunes que nos interesan.</p>
    <h3>Muestra aleatoria</h3>
    <p>Una muestra aleatoria es un subconjunto de la poblaci√≥n seleccionado de tal manera que cada individuo tiene la misma probabilidad de ser elegido. Se utiliza para obtener informaci√≥n sobre la poblaci√≥n sin tener que estudiar a todos los individuos.</p>
    <h3>Par√°metros aleatorios </h3>
    <p> Los par√°metros aleatorios son caracter√≠sticas desconocidas de la poblaci√≥n que se estiman a partir de una muestra. Se representan con letras griegas, como Œº para la media y œÉ para la desviaci√≥n est√°ndar.</p>
    
    <h2>1.2 Descripci√≥n de datos</h2>
    <h3>Datos agrupados</h3>
    <p> Los datos agrupados son aquellos que se presentan en intervalos o clases. Se utilizan cuando se tienen muchos datos o cuando los datos no son precisos.</p>
    <h3>Datos no agrupados</h3>
    <p>Los datos no agrupados son aquellos que se presentan en su valor individual. Se utilizan cuando se tienen pocos datos o cuando los datos son precisos.</p>
    <h3>Frecuencia de clase</h3>
    <p>La frecuencia de clase es el n√∫mero de individuos que caen en un intervalo o clase.</p>
    <h3>Frecuencia relativa</h3>
    <p> La frecuencia relativa es la proporci√≥n de individuos que caen en un intervalo o clase. Se calcula dividiendo la frecuencia de clase por el tama√±o total de la muestra.</p>
    <h3>Punto medio </h3>
    <p>El punto medio es el valor promedio de un intervalo o clase. Se calcula sumando los l√≠mites inferior y superior del intervalo y dividiendo por dos.</p>
    <h3>L√≠mites</h3>
    <p>Los l√≠mites son los valores que definen un intervalo o clase. El l√≠mite inferior es el valor m√°s peque√±o del intervalo, mientras que el l√≠mite superior es el valor m√°s grande del intervalo.</p>
    
    <h2>1.3 Medidas de tendencia central</h2>
    <h3>Media aritm√©tica</h3>
    <p>La media aritm√©tica es la suma de todos los valores de una muestra dividida por el tama√±o de la muestra. Se representa con la letra Œº o XÃÖ.</p>
    <h3>Media geom√©trica</h3>
    <p> La media geom√©trica es el n-√©simo ra√≠z del producto de todos los valores de una muestra. Se representa con la letra G.</p>
    <h3>Media ponderada</h3>
    <p> La media ponderada es la suma de los productos de cada valor de una muestra por su peso correspondiente dividida por la suma de los pesos. Se utiliza cuando los datos tienen diferente importancia.</p>
    <h3>Mediana </h3>
    <p>La mediana es el valor que divide a la muestra ordenada en dos partes de igual tama√±o. Se representa con la letra M. </p>
    <h3>Moda</h3>
    <p>La moda es el valor que aparece con mayor frecuencia en una muestra. Se representa con la letra Mo.</p>
    <h3>Medidas de dispersi√≥n </h3>
    <p> Las medidas de dispersi√≥n indican qu√© tan dispersos est√°n los datos alrededor de la medida de tendencia central. Las medidas de dispersi√≥n m√°s comunes son la varianza, la desviaci√≥n est√°ndar, la desviaci√≥n media y la desviaci√≥n mediana.</p>
    <h3>Varianza</h3>
    <p>La varianza es el promedio del cuadrado de las desviaciones de cada valor de la muestra respecto a la media. Se representa con la letra œÉ^2.</p>
    <h3>Desviaci√≥n est√°ndar</h3>
    <p> La desviaci√≥n est√°ndar es la ra√≠z cuadrada de la varianza. Se representa con la letra œÉ.</p>
    <h3>Desviaci√≥n media</h3>
    <p>La desviaci√≥n media es el promedio de las distancias absolutas de cada valor de la muestra respecto a la media.</p>
    <h3>Desviaci√≥n mediana </h3>
    <p> La desviaci√≥n mediana es la mediana de las distancias absolutas de cada valor de la muestra respecto a la mediana.</p>
    <h3>Rango</h3>
    <p>El rango es la diferencia entre el valor m√°ximo y el valor m√≠nimo de una muestra.</p>
   
    <h2>1.4 Par√°metros para datos agrupados</h2>
    <h3>Media muestral agrupada </h3>
    <p> La media muestral agrupada se calcula utilizando la siguiente f√≥rmula:</p>
    <p>Media muestral agrupada = Œ£(fi * xi) / Œ£fi</p>
    <p>Donde:</p>
    <ul>
        <li>fi es la frecuencia de la clase i</li>
        <li>xi es el punto medio de la clase i</li>
    </ul>
    <h3>Mediana muestral agrupada</h3>
    <p>La mediana muestral agrupada se calcula dividiendo la poblaci√≥n en dos partes iguales y luego identificando la clase en la que cae la mediana. La mediana muestral agrupada se calcula utilizando la siguiente f√≥rmula:</p>
   <p>Mediana muestral agrupada = l√≠mite inferior de la clase + (h(N/2 - Œ£fi) / fi)</p>
   <p>Donde:</p>
    <ul>
        <li>N es el total de elementos de la muestra.</li>
        <li>Œ£fi es la suma de las frecuencias acumuladas hasta la clase anterior a la que contiene la mediana.</li>
        <li>h es el ancho de la clase que contiene la mediana.</li>
        <li>fi es la frecuencia de la clase que contiene la mediana.</li>
    </ul> 
   <h3>Moda muestral agrupada </h3>
    <p>La moda muestral agrupada es la clase que tiene la mayor frecuencia.</p>
   
    <h2>1.5 Distribuci√≥n de frecuencias</h2>
    <p>Una distribuci√≥n de frecuencias es una tabla que muestra la distribuci√≥n de los valores de un conjunto de datos en clases o intervalos. La distribuci√≥n de frecuencias incluye la frecuencia de cada clase, la frecuencia relativa de cada clase y el porcentaje de cada clase.</p>
    <h3>Componentes de una distribuci√≥n de frecuencias</h3>
    <ul>
        <li>Clases o intervalos: Son los grupos en los que se dividen los datos.</li>
        <li>Frecuencia de clase: Es el n√∫mero de elementos que caen en cada clase o intervalo.</li>
        <li>Frecuencia relativa: Es la proporci√≥n de elementos que caen en cada clase o intervalo con respecto al total de elementos. Se calcula dividiendo la frecuencia de clase por el total de elementos.</li>
        <li>Porcentaje: Es la frecuencia relativa expresada en tanto por ciento. Se calcula multiplicando la frecuencia relativa por 100.</li>
    </ul>
    
    <h2>1.6 T√©cnicas de agrupaci√≥n de datos</h2>
    <p>La agrupaci√≥n de datos es el proceso de dividir un conjunto de datos en clases o intervalos. La elecci√≥n del n√∫mero y el ancho de las clases es importante para obtener una buena representaci√≥n de los datos.</p>
    <h3>Factores a considerar al elegir el n√∫mero y el ancho de las clases</h3>
    <ul>
        <li>El tama√±o del conjunto de datos: Cuanto mayor sea el conjunto de datos, m√°s clases se pueden utilizar.</li>
        <li>La variabilidad de los datos: Si los datos son muy variables, se necesitar√°n m√°s clases para capturarlos adecuadamente.</li>
        <li>El prop√≥sito del an√°lisis: El prop√≥sito del an√°lisis tambi√©n influir√° en la elecci√≥n del n√∫mero y el ancho de las clases.</li>
    </ul>
    <h3>M√©todos para agrupar datos</h3>
    <ul>
        <li>Agrupaci√≥n por igual ancho: Este m√©todo consiste en dividir el rango de los datos en clases de igual ancho.</li>
        <li>Agrupaci√≥n por frecuencias iguales: Este m√©todo consiste en dividir los datos en clases de tal manera que cada clase tenga aproximadamente el mismo n√∫mero de elementos.</li>
        <li>Agrupaci√≥n por percentiles: Este m√©todo consiste en dividir los datos en clases de tal manera que cada clase contenga un porcentaje espec√≠fico de la poblaci√≥n.</li>
    </ul>

    <h2>1.7 T√©cnicas de muestreo</h2>
    <p>El muestreo es el proceso de seleccionar un subconjunto de la poblaci√≥n para estudiar las caracter√≠sticas de toda la poblaci√≥n. El objetivo del muestreo es obtener una muestra representativa de la poblaci√≥n, es decir, una muestra que refleje las caracter√≠sticas de la poblaci√≥n en general.</p>
    <h3>Tipos de muestreo</h3>
    <ul>
        <li>Muestreo aleatorio simple: En este tipo de muestreo, cada elemento de la poblaci√≥n tiene la misma probabilidad de ser seleccionado.</li>
        <li>Muestreo estratificado: En este tipo de muestreo, la poblaci√≥n se divide en estratos o subgrupos, y luego se selecciona una muestra aleatoria de cada estrato.</li>
        <li>Muestreo sistem√°tico: En este tipo de muestreo, se selecciona un elemento de la poblaci√≥n como punto de partida, y luego se seleccionan otros elementos a intervalos regulares.</li>
        <li>Muestreo por conglomerados: En este tipo de muestreo, la poblaci√≥n se divide en conglomerados o grupos, y luego se selecciona una muestra aleatoria de conglomerados.</li>
    </ul>
    <p>La elecci√≥n del tipo de muestreo adecuado depender√° del tama√±o y la estructura de la poblaci√≥n, del prop√≥sito del estudio y de los recursos disponibles.</p>
    
    <h2>1.8 Histogramas</h2>
    <p>Un histograma es una representaci√≥n gr√°fica de la distribuci√≥n de frecuencias de un conjunto de datos. Se construye utilizando barras rectangulares, donde la altura de cada barra es proporcional a la frecuencia de la clase correspondiente. A continuaci√≥n un ejemplo:</p>
    <center>
    <img  src="https://www.leadingedgegroup.com/wp-content/uploads/2017/11/histogram.jpg.webp" >
</center>
    <h3>Componentes de un histograma</h3>
    <ul>
        <li>Eje de abscisas: Representa las clases o intervalos de los datos.</li>
        <li>Eje de ordenadas: Representa la frecuencia o la frecuencia relativa de los datos.</li>
        <li>Barras rectangulares: Cada barra rectangular representa una clase o intervalo de los datos. La altura de la barra es proporcional a la frecuencia o la frecuencia relativa de la clase.</li>
      </ul>
      
    <h3>Pasos para construir un histograma</h3>
    <ol>
        <li>Determinar las clases o intervalos: El primer paso es determinar las clases o intervalos en que se van a agrupar los datos. La elecci√≥n del n√∫mero y el ancho de las clases es importante para obtener una buena representaci√≥n de los datos.</li>
        <li>Calcular la frecuencia de cada clase: Una vez que se han determinado las clases, se calcula la frecuencia de cada clase. La frecuencia de clase es el n√∫mero de elementos que caen en cada clase o intervalo.</li>
        <li>Dibujar el eje de abscisas: El eje de abscisas se dibuja en la parte inferior del gr√°fico. Se debe dividir en intervalos iguales que representen las clases o intervalos de los datos.</li>
        <li>Dibujar el eje de ordenadas: El eje de ordenadas se dibuja en el lado izquierdo del gr√°fico. Se debe escalar de acuerdo a la frecuencia o la frecuencia relativa de los datos.</li>
        <li>Dibujar las barras rectangulares: Se dibuja una barra rectangular para cada clase o intervalo. La altura de la barra debe ser proporcional a la frecuencia o la frecuencia relativa de la clase.</li>
        <li>Etiquetar el histograma: Se debe etiquetar el eje de abscisas con los nombres de las clases o intervalos, y el eje de ordenadas con la frecuencia o la frecuencia relativa. Tambi√©n se debe poner un t√≠tulo al histograma.</li>
      </ol>
      
    <h3>Interpretaci√≥n de histogramas</h3>
    <p>Los histogramas se pueden utilizar para interpretar la distribuci√≥n de los datos. Por ejemplo, un histograma sim√©trico indica que los datos est√°n distribuidos uniformemente alrededor de la media. Un histograma asim√©trico a la derecha indica que los datos est√°n concentrados en la parte izquierda del gr√°fico, mientras que un histograma asim√©trico a la izquierda indica que los datos est√°n concentrados en la parte derecha del gr√°fico. Un histograma con dos o m√°s picos indica que los datos son multimodales.</p>
    <p>Los histogramas son una herramienta √∫til para explorar y visualizar datos. Se pueden utilizar para identificar patrones, tendencias y anomal√≠as en los datos.</p>
    <h3>Actividad Desarrollada</h3>
    <P>Este Notebook explora diversos conceptos fundamentales y t√©cnicas avanzadas en el campo de la estad√≠stica y el an√°lisis de datos, implementados utilizando Python y sus bibliotecas especializadas. Cada secci√≥n del Notebook incluye ejemplos pr√°cticos implementados en Python, utilizando bibliotecas como NumPy y Pandas, proporcionando una gu√≠a detallada para aplicar estos conceptos en proyectos reales de an√°lisis de datos. <a href="testGlobal.html" > Para explorar m√°s a fondo estos temas y aplicar las t√©cnicas discutidas anteriormente, puedes acceder al Notebook completo aqu√≠</a></P>
    


    <h1>2 Fundamentos de la Teoria de Probabilidad</h1>

    <h2>2.1 T√©cnicas de Conteo</h2>
    <p>Las t√©cnicas de conteo son herramientas matem√°ticas que permiten determinar el n√∫mero de resultados posibles en situaciones que involucran la elecci√≥n o disposici√≥n de elementos. Estas t√©cnicas son fundamentales en √°reas como la probabilidad, la estad√≠stica y la combinatoria.</p>
    <h3>2.1.1 Principio aditivo</h3>
    <p>El principio aditivo establece que si hay n maneras de realizar una acci√≥n y m maneras de realizar otra acci√≥n, entonces hay n + m maneras de realizar ambas acciones de forma independiente. En otras palabras, si A y B son eventos disjuntos (no pueden ocurrir al mismo tiempo), entonces la probabilidad de que ocurra A o B es la suma de sus probabilidades individuales:</p>
    <p>P(A o B) = P(A) + P(B)    </p>
    <p>Ejemplo: Supongamos que una persona debe elegir entre dos restaurantes para cenar: un restaurante italiano y un restaurante chino. Si hay 5 opciones de platos en el restaurante italiano y 7 opciones de platos en el restaurante chino, ¬øcu√°ntas opciones de plato tiene la persona en total?</p>
    <p> Soluci√≥n: Aplicando el principio aditivo, la persona tiene 5 + 7 = 12 opciones de plato en total.</p>
    <h3>2.1.2 Principio multiplicativo</h3>
    <p>El principio multiplicativo establece que si hay n maneras de realizar una acci√≥n y luego hay m maneras de realizar otra acci√≥n dependiente de la primera, entonces hay n * m maneras de realizar ambas acciones en conjunto. En otras palabras, si A y B son eventos dependientes (la ocurrencia de uno afecta la probabilidad del otro), entonces la probabilidad de que ocurran A y B es la probabilidad de A multiplicada por la probabilidad de B dado que A ya ha ocurrido:</p>
    <p>P(A y B) = P(A) * P(B | A)</p>
    <h3>2.1.3 Notaci√≥n Factorial</h3>
    <p>La notaci√≥n factorial se utiliza para representar el producto de una secuencia de n√∫meros enteros positivos consecutivos. El factorial de n, que se denota como n!, se define como:</p>
    <p>n! = n * (n - 1) * (n - 2) * ... * 2 * 1</p>
    <p>Por ejemplo, 5! = 5 * 4 * 3 * 2 * 1 = 120.</p>
    <p>La notaci√≥n factorial es especialmente √∫til en el contexto de las permutaciones y combinaciones.</p>
    <h3>2.1.4 Permutaciones</h3>
    <p>La permutaci√≥n es una t√©cnica de conteo que permite calcular las posibles ordenaciones de los elementos de un conjunto o n√∫mero de elementos del espacio muestral de un experimento aleatorio. En esta t√©cnica de conteo se considera que existe el orden en la muestra, pero no es posible repetir ning√∫n elemento de la poblaci√≥n en su conformaci√≥n. Se puede calcular utilizando la siguiente f√≥rmula:</p>
    <p>nPr=(n!)/(n-r)!</p>
    <h3>2.1.5 Combinaciones</h3>
    <p>Una combinaci√≥n es una selecci√≥n de k elementos de un conjunto de n elementos, sin importar el orden en que se seleccionen. El n√∫mero de combinaciones de n elementos tomados de k en k se denota como nCk y se puede calcular utilizando la siguiente f√≥rmula:</p>
    <p>nCk = n! / (k! * (n - k)!)</p>
    <h3>2.1.6 Diagrama de √Årbol</h3>
    <p>Un diagrama de √°rbol es una herramienta visual que se utiliza para representar las diferentes posibilidades en situaciones que involucran decisiones sucesivas. Cada rama del √°rbol representa una elecci√≥n, y las probabilidades se pueden asignar a cada rama.</p>
    <h3>2.1.7 Teorema del Binomio</h3>
    <p>El Teorema del Binomio, tambi√©n conocido como Binomio de Newton, es una f√≥rmula matem√°tica que describe c√≥mo se expande la potencia "n" de un binomio (una expresi√≥n con dos t√©rminos). La f√≥rmula se expresa como:</p>
    <p>(a + b)^n = Œ£(k=0; n) (nCk) * a^(n-k) * b^k</p>
    <p>Donde:</p>
    <ul>
        <li>(a + b)<sup>n</sup> representa el binomio "a + b" elevado a la potencia "n".</li>
        <li>Œ£ indica una sumatoria, lo que significa que la expresi√≥n representa la suma de todos los t√©rminos que se obtienen al expandir el binomio.</li>
        <li>(nCk) es el coeficiente binomial de "n" elegir "k", que se calcula como n! / (k! * (n-k)!). Este coeficiente determina el n√∫mero de veces que aparece cada t√©rmino en la expansi√≥n.</li>
        <li>a<sup>(n-k)</sup> representa "a" elevado a la potencia "n-k". Esta potencia indica la contribuci√≥n de "a" en cada t√©rmino de la expansi√≥n.</li>
        <li>b<sup>k</sup> representa "b" elevado a la potencia "k". Esta potencia indica la contribuci√≥n de "b" en cada t√©rmino de la expansi√≥n.</li>
      </ul>

    <h2>2.2 Teor√≠a elemental de probabilidad</h2>
    <p>La teor√≠a elemental de la probabilidad se basa en conceptos b√°sicos para cuantificar la probabilidad de que ocurra un evento en un experimento aleatorio. Se define la probabilidad de un evento "A" como la raz√≥n entre el n√∫mero de resultados favorables a "A" y el n√∫mero total de resultados posibles en el espacio muestral. Matem√°ticamente, se expresa como:</p>
    <p>P(A) = n(A) / n(S)</p>
    <p>Donde:</p>
    <ul>
        <li>P(A) representa la probabilidad del evento "A".</li>
        <li>n(A) es el n√∫mero de resultados favorables a "A".</li>>
        <li>n(S) es el n√∫mero total de resultados posibles en el espacio muestral "S".</li>
      </ul>
    <h3>Propiedades b√°sicas de la probabilidad:</h3>
    <ul>
          <li>0 ‚â§ P(A) ‚â§ 1: La probabilidad de cualquier evento debe estar entre 0 y 1. Un valor de 0 indica que el evento es imposible, mientras que 1 indica que es seguro que ocurra.</li>
          <li>P(S) = 1: La probabilidad del espacio muestral completo siempre es 1.</li>
          <li>Si A y B son eventos mutuamente excluyentes, entonces P(A ‚à™ B) = P(A) + P(B). Eventos mutuamente excluyentes son aquellos que no pueden ocurrir simult√°neamente. La uni√≥n (‚à™) representa la probabilidad de que ocurra al menos uno de los eventos.</li>
          <li>Si A y B son eventos independientes, entonces P(A ‚à© B) = P(A) * P(B). Eventos independientes son aquellos en los que la ocurrencia de uno no afecta la probabilidad del otro. La intersecci√≥n (‚à©) representa la probabilidad de que ocurran ambos eventos simult√°neamente.</li>
    </ul>
    <h2>2.3 Probabilidad de Eventos: Definici√≥n de espacio muestral, definici√≥n de evento, simbolog√≠a, uni√≥n, intersecci√≥n, diagramas de Venn.</h2>
    <h3>Definici√≥n de espacio muestral</h3>
    <p>El espacio muestral, denotado por Œ©, es el conjunto que contiene todos los resultados posibles de un experimento aleatorio. En otras palabras, es la colecci√≥n completa de todos los eventos que pueden ocurrir. Cada resultado en el espacio muestral se llama evento elemental.</p>
    <p>Ejemplo: Si lanzamos una moneda, el espacio muestral Œ© ser√≠a {cara, cruz}.</p>
    <h3>Definici√≥n de evento</h3>
    <p>Un evento es un subconjunto del espacio muestral. Es un conjunto de resultados posibles que nos interesa considerar. Puede ser un solo resultado elemental o una combinaci√≥n de ellos.</p>
    <p>Ejemplo: Si lanzamos una moneda, el evento "obtener cara" ser√≠a {cara}.</p>
    <h3>Simbolog√≠a</h3>
    <ul>
        <li>Œ©: Espacio muestral</li>
        <li>A: Evento</li>
        <li>AÃÖ: Complemento de A (conjunto de resultados en Œ© que no est√°n en A)</li>
        <li>A ‚à™ B: Uni√≥n de A y B (conjunto de resultados que est√°n en A o en B o en ambos)</li>
        <li>A ‚à© B: Intersecci√≥n de A y B (conjunto de resultados que est√°n en A y en B)</li>
    </ul>
    <h3>Diagrama de Venn</h3>
    <p>Un diagrama de Venn es una representaci√≥n gr√°fica de dos o m√°s eventos. Los eventos se representan por c√≠rculos o regiones, y la superposici√≥n de las regiones indica la intersecci√≥n de los eventos.</p>
    
    <h2>2.4 Probabilidad con T√©cnicas de Conteo: Axiomas, Teoremas</h2>
    <h3>Axiomas</h3>
    <p>Los axiomas de la probabilidad son principios b√°sicos que definen las propiedades de la probabilidad. Los tres axiomas principales son:</p>
    <ul>
        <li>No negatividad: P(A) ‚â• 0 para todo evento A.        </li>
        <li>Certeza: P(Œ©) = 1.        </li>
        <li>Ley de la aditividad: Si A y B son eventos mutuamente excluyentes (no tienen resultados en com√∫n), entonces P(A ‚à™ B) = P(A) + P(B).</li>
    </ul>
    <h3>Teoremas</h3>
    <p>Existen varios teoremas importantes en probabilidad con t√©cnicas de conteo, como:</p>
    <ul>
        <li>Teorema de la multiplicaci√≥n: Si un experimento se compone de n pasos sucesivos e independientes, la probabilidad de un resultado espec√≠fico es el producto de las probabilidades de cada paso individual.</li>
        <li>Permutaciones: El n√∫mero de formas de ordenar n objetos distintos es n!.        </li>
        <li>El n√∫mero de formas de seleccionar k objetos de un conjunto de n objetos distintos sin importar el orden es nCk = n! / (k!(n - k)!).</li>
    </ul>
    
    <h2>2.5 Probabilidad condicional: Dependiente, Independiente</h2>
    <h3>Dependiente</h3>
    <p>Dos eventos A y B se consideran dependientes si la probabilidad de uno afecta la probabilidad del otro. En otras palabras, si saber que ha ocurrido A cambia la probabilidad de que ocurra B.

        Ejemplo: Sacar dos cartas de una baraja sin reponer. La probabilidad de sacar un rey en la segunda carta depende de si el rey se sac√≥ en la primera carta.</p>
    
    <h3>Independiente</h3>
    <p>Dos eventos A y B se consideran independientes si la probabilidad de uno no afecta la probabilidad del otro. En otras palabras, saber que ha ocurrido A no cambia la probabilidad de que ocurra B.

        Ejemplo: Lanzar dos monedas. La probabilidad de obtener cara en la segunda moneda es la misma independientemente de si se obtuvo cara o cruz en la primera moneda.</p>
   
    <h2>2.6 Ley multiplicativa</h2>
    <p>La ley multiplicativa establece que la probabilidad de que ocurran dos eventos independientes A y B es el producto de sus probabilidades individuales:    </p>
    <p>P(A ‚à© B) = P(A) * P(B)    </p>

    <h2>2.7 Eventos independientes: Regla de Bayes</h2>
    <p>La regla de Bayes es un teorema que permite calcular la probabilidad condicional de un evento A sabiendo que ha ocurrido otro evento B, cuando los eventos son independientes. Se expresa como:</p>
    <p>P(A | B) = (P(B | A) * P(A)) / P(B)</p>
    <ul>
        <li>P(B | A) es la probabilidad condicional de B dado A, es decir, la probabilidad de que ocurra B sabiendo que ya ha ocurrido A.</li>
        <li>P(B) es la probabilidad marginal de B, es decir, la probabilidad de que ocurra B sin tener en cuenta si ha ocurrido A o no.</li>
    </ul>
    <h3>Interpretaci√≥n de histogramas</h3>
    <p>Los histogramas se pueden utilizar para interpretar la distribuci√≥n de los datos. Por ejemplo, un histograma sim√©trico indica que los datos est√°n distribuidos uniformemente alrededor de la media. Un histograma asim√©trico a la derecha indica que los datos est√°n concentrados en la parte izquierda del gr√°fico, mientras que un histograma asim√©trico a la izquierda indica que los datos est√°n concentrados en la parte derecha del gr√°fico. Un histograma con dos o m√°s picos indica que los datos son multimodales.</p>
    <p>Los histogramas son una herramienta √∫til para explorar y visualizar datos. Se pueden utilizar para identificar patrones, tendencias y anomal√≠as en los datos.</p>
   
   
    <h3>Actividad Desarrollada</h3>
    <P>Este Notebook aborda una serie de temas fundamentales en teor√≠a de conteo y probabilidad, proporcionando una base s√≥lida para comprender y aplicar estos conceptos en contextos pr√°cticos. <a href="EjerciciosTecnicasDeConteo.html" >Para explorar m√°s a fondo estos temas y aplicar las t√©cnicas discutidas, puedes acceder al Notebook completo aqu√≠</a></P>
 
   
    <h1>3 Variables Aleatorias</h1>
    <h2>3.1 Variables aleatorias discretas</h2>
    <p>Las variables aleatorias discretas son aquellas en que el n√∫mero de valores posibles que toman es finito o infinito, pero que puede numerarse</p>
    <h3>3.1.1 Distribuci√≥n de probabilidad en forma general</h3>
    <p>Una variable aleatoria discreta X se define por su funci√≥n de probabilidad, P(x), que asigna a cada valor posible x de X una probabilidad P(x)‚â•0, de tal manera que ‚àë x‚ààX P(x)=1, donde X es el conjunto de valores posibles de X.</p>
    <p>La funci√≥n de probabilidad P(x) puede representarse mediante una tabla de frecuencias o una gr√°fica de barras.</p>
    <img src="ProbabilidadDescriptiva.png" class="imagenesFormulas">
    <h3>3.1.2 Valor esperado</h3>
    <p>La media o valor esperado es una medida de localizaci√≥n central de la variable aleatoria. Se calcula de la manera siguiente:</p>
    <img src="valorEsperado.png" class="imagenesFormulas">
    <p>es decir, es un promedio ponderado de los valores que toma la variable aleatoria (Xi ), donde las ponderaciones (o pesos) son las probabilidades [P(Xi )].</p>
    <h3>3.1.3 Variancia, desviaci√≥n est√°ndar</h3>
    <p>La varianza y la desviaci√≥n est√°ndar son medidas de dispersi√≥n o variabilidad de la variable aleatoria. La primera se calcula de la siguiente manera:</p>
    <img src="varianza.png" class="imagenesFormulas">
    <p>En otras palabras, es el promedio ponderado de las distancias al cuadrado de cada valor de la variable aleatoria respecto a su media. Esto indica cu√°n alejados est√°n los valores en relaci√≥n con la media. Se eleva al cuadrado para hacer m√°s evidente esa distancia (variabilidad). Tambi√©n puede calcularse as√≠:</p>
    <img src="varianza2.png" class="imagenesFormulas">
    <p>Como el resultado de la varianza se expresa en unidades al cuadrado, determinamos la desviaci√≥n est√°ndar calculando s√≥lo la ra√≠z cuadrada de la varianza.</p>
    <h3>3.1.4 Funci√≥n acumulada</h3>
    <p>a funci√≥n acumulada de una variable aleatoria discreta representa la probabilidad de que la variable tome un valor menor o igual a un valor espec√≠fico x. Se define como:</p>
    <img src="funcionAcumulada.png" class="imagenesFormulas">
    <p>La funci√≥n acumulada es una funci√≥n no decreciente que va de 0 a 1.    </p><br>
    <h3>Actividad Desarrollada</h3>
    <p>En este video exploramos conceptos clave relacionados con variables aleatorias discretas y sus distribuciones de probabilidad, proporcionando una comprensi√≥n fundamental para analizar y modelar fen√≥menos en diversas disciplinas. </p>
    <a href="https://www.canva.com/design/DAGJ0YwZ2uI/q6RqYVMgUmdtzD41fi2GwA/view?utm_content=DAGJ0YwZ2uI&utm_campaign=designshare&utm_medium=link&utm_source=recording_view">3.1 Variables aleatorias discretas</a>
   


    <h2>3.2 Variables aleatorias Continuas</h2>
    <p> En estad√≠stica, una variable aleatoria continua es aquella que puede tomar infinitos valores dentro de un intervalo real. A diferencia de las variables aleatorias discretas, que solo pueden tomar valores espec√≠ficos, las variables continuas pueden tomar cualquier valor dentro de un rango definido</p>
    <h3>3.2.1 Distribuci√≥n de probabilidad en forma general</h3>
    <p>Las variables aleatorias continuas se caracterizan por tener un conjunto infinito no numerable de valores posibles dentro de un intervalo. Su distribuci√≥n de probabilidad se define mediante una funci√≥n de densidad de probabilidad, f(x), que asigna a cada valor x en el intervalo de valores posibles X una densidad de probabilidad f(x)‚â•0, cumpliendo la condici√≥n de que la integral de la densidad de probabilidad en todo el intervalo sea igual a 1:</p>
    <img src="probabilidadContinuas.png" class="imagenesFormulas">
    <h3>3.2.2 Valor esperado</h3>
    <p>Es una medida de localizaci√≥n central de la variable aleatoria. Se calcula de la forma siguiente:</p>
    <img src="valorEsperadoContinuas.png" class="imagenesFormulas">
    <h3>3.2.3 Variancia, desviaci√≥n est√°ndar</h3>
    <p>Son medidas de dispersi√≥n o variabilidad de la variable aleatoria. Se calculan de esta  manera:</p>
    <img src="varianzaContinuas.png" class="imagenesFormulas">
    <p>Cabe recordar que la varianza tambi√©n puede calcularse as√≠:</p>
    <img src="varianza continuas2.png" class="imagenesFormulas">
    <p>De este modo determinamos la desviaci√≥n est√°ndar calculando √∫nicamente la ra√≠z cuadrada de la varianza.</p>
    <h3>3.2.4 Funci√≥n acumulada</h3>
    <p>La funci√≥n acumulada de una variable aleatoria continua representa la probabilidad de que la variable tome un valor menor o igual a un valor espec√≠fico x. Se define como:</p>
    <img src="funcionAcumuladaContinuas.png" class="imagenesFormulas">
    <p>La funci√≥n acumulada es una funci√≥n no decreciente que va de 0 a 1.</p>
    <h3>3.2.5 C√°lculos de probabilidad</h3>
    <p>Para calcular probabilidades relacionadas con una variable aleatoria continua, se utiliza la funci√≥n acumulada. Por ejemplo, para calcular la probabilidad de que la variable aleatoria X tome un valor entre a y b, se utiliza la siguiente f√≥rmula:</p>
    <img src="CalculosDeProb.png" class="imagenesFormulas"><br><br><br>
    <h3>Actividad Desarrollada</h3>
    <p>En este video exploramos conceptos clave relacionados con variables aleatorias continuas y sus distribuciones de probabilidad, proporcionando una comprensi√≥n fundamental para analizar y modelar fen√≥menos en diversas disciplinas. </p>
    <a href="https://www.canva.com/design/DAGJ0Oiu_A0/Xd8TrqEY2sCVZzCOM9FFCA/view?utm_content=DAGJ0Oiu_A0&utm_campaign=designshare&utm_medium=link&utm_source=recording_view " >3.2 Variables aleatorias Continuas Video</a>





    <h1>4 Distribuciones de Probabilidad</h1>
    <p>En el √°mbito de la probabilidad y la estad√≠stica, las distribuciones de probabilidad desempe√±an un papel fundamental para modelar el comportamiento de variables aleatorias en diversos contextos. Estas distribuciones permiten cuantificar la probabilidad de que una variable aleatoria tome un valor espec√≠fico o se encuentre dentro de un intervalo particular. A continuaci√≥n, se presenta una descripci√≥n m√°s detallada de algunas de las distribuciones de probabilidad m√°s comunes, adoptando un estilo t√©cnico y formal:</p>
    <h2>4.1 Funci√≥n de probabilidad </h2>
    <p>La funci√≥n de probabilidad es una funci√≥n matem√°tica que asigna a cada valor posible de una variable aleatoria X su probabilidad de ocurrencia. Se representa con la notaci√≥n P(X = x) o f(x) para una variable discreta, y con F(x) para una variable continua. La funci√≥n de probabilidad debe cumplir las siguientes propiedades:</p>
    <ul>
        <li>P(X ‚â§ a) ‚â§ 1 para todo valor real a.</li>
        <li>Si X es discreta, entonces P(X = x) ‚â• 0 para todo valor posible de x.</li>
        <li>Si X es continua, entonces F(x) es no decreciente y F(a) = 0 para todo a < m√≠nimo valor posible de X.</li>
        <li>Si X es continua, entonces F(b) = 1 para todo b > m√°ximo valor posible de X.</li>
    </ul>
    <p>La funci√≥n de probabilidad es fundamental para calcular probabilidades de eventos relacionados con la variable aleatoria X. Su formula es: \( P(X = x_i) = p_i \) con \( \sum p_i = 1 \).</p>
   
   
    <h2>4.2 Distribuci√≥n binomial</h2>
    <p>La distribuci√≥n binomial describe la probabilidad de obtener un n√∫mero espec√≠fico de "√©xitos" en n experimentos independientes, donde cada experimento tiene la misma probabilidad de √©xito p. Se utiliza cuando:</p>
    <ul>
        <li>La variable aleatoria X representa el n√∫mero de √©xitos.</li>
        <li>X es discreta con valores posibles 0, 1, 2, ..., n.</li>
        <li>Los experimentos son independientes.</li>
        <li>La probabilidad de √©xito en cada experimento es la misma (p).</li>
    </ul>
    <p>La funci√≥n de probabilidad de la distribuci√≥n binomial para X = k √©xitos en n experimentos es:</p>
    <img src="binomial.png" class="imagenesFormulas">
    <p>Donde:</p><ul>
        <li>nCk es el n√∫mero de combinaciones de n elementos tomados de k en k.</li>
        <li>p es la probabilidad de √©xito en cada experimento.</li>
        <li>n: N√∫mero de ensayos</li>
        <li>k: N√∫mero de √©xitos deseados</li>
        <li>(1-p) es la probabilidad de fracaso en cada experimento.</li>
    </ul>
   <p>¬øCuando usar?</p>
   <p>Experimentos de Bernoulli con dos resultados posibles</p>
   
    <h2>4.3 Distribuci√≥n hipergeom√©trica</h2>
    <p>La distribuci√≥n hipergeom√©trica describe la probabilidad de obtener un n√∫mero espec√≠fico de "√©xitos" en n experimentos sin reemplazo, donde la poblaci√≥n inicial tiene N elementos, de los cuales K son √©xitos. Se utiliza cuando:</p>
    <ul>
        <li>La variable aleatoria X representa el n√∫mero de √©xitos en la muestra.</li>
        <li>X es discreta con valores posibles 0, 1, 2, ..., min(n, K).</li>
        <li>Los experimentos son sin reemplazo.</li>
        <li>La poblaci√≥n inicial es finita y conocida (N elementos).</li>
        <li>La probabilidad de √©xito en cada experimento no es constante (depende del n√∫mero de √©xitos restantes en la poblaci√≥n).</li>
    </ul>
    <p>La funci√≥n de probabilidad de la distribuci√≥n hipergeom√©trica para X = k √©xitos en una muestra de n elementos es:</p>
    <img src="hipergeometrica.png" class="imagenesFormulas">
    <p>Donde:</p>
    <ul>
        <li>N: tama√±o de la poblaci√≥n</li>
        <li>K: n√∫mero de √©xitos en la poblaci√≥n</li>
        <li>n: tama√±o de la muestra</li>
        <li>k: n√∫mero de √©xitos en la muestra</li>
        <li>\(\binom{a}{b}\): coeficiente binomial</li>
    </ul>
    <p>¬øCuando usar?</p>
   <p>Muestreo sin reemplazo de una poblaci√≥n finita</p>
    <h2>4.4 Distribuci√≥n de Poisson</h2>
    <p>La distribuci√≥n de Poisson describe la probabilidad de observar un n√∫mero espec√≠fico de eventos en un intervalo de tiempo fijo, suponiendo que los eventos ocurren de forma independiente y con una tasa constante. Se utiliza cuando:</p>
    <ul>
        <li>La variable aleatoria X representa el n√∫mero de eventos en un intervalo de tiempo fijo.</li>
        <li>X es discreta con valores posibles 0, 1, 2, ...</li>
        <li>Los eventos ocurren de forma independiente.</li>
        <li>La tasa de eventos (Œª) es constante en el intervalo de tiempo.</li>
    </ul>
    <p>La funci√≥n de probabilidad de la distribuci√≥n de Poisson para X = k eventos en un intervalo de tiempo con tasa Œª es:</p>
    <img src="poisson.png" class="imagenesFormulas">
    <p>Donde: </p>
    <ul>
        <li>\(\lambda\): tasa promedio de ocurrencia de eventos</li>
        <li>k: n√∫mero de eventos observados</li>
        <li>e: base del logaritmo natural</li>
        <li>k!: factorial de \( k \)</li>
    </ul>
    <p>Su media se calcula como: <br>
        \(\lambda\) <br> Y su varianza como: <br>
    \(\lambda\)</p>
    <p>¬øCuando usar?</p>
   <p>Modelar eventos raros y discretos en un intervalo de tiempo o espacio</p>
    <h2>4.5 Distribuci√≥n normal</h2>
    <p>La distribuci√≥n normal, tambi√©n conocida como distribuci√≥n gaussiana, describe la probabilidad de que una variable aleatoria continua X tome un valor dentro de un intervalo espec√≠fico. Se caracteriza por su media (Œº) y su desviaci√≥n est√°ndar (œÉ).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La curva de densidad de probabilidad es sim√©trica alrededor de la media (Œº).</li>
        <li>El 68% de los datos se encuentran dentro de un intervalo de 1 desviaci√≥n est√°ndar (Œº ¬± œÉ) de la media.</li>
        <li>El 95% de los datos se encuentran dentro de un intervalo de 2 desviaciones est√°ndar (Œº ¬± 2œÉ) de la media.</li>
        <li>El 99.7% de los datos se encuentran dentro de un intervalo de 3 desviaciones est√°ndar (Œº ¬± 3œÉ) de la media.</li>
    </ul>
    <p>Formula:</p>
    <img src="normal.png" class="imagenesFormulas">
    <p>Donde: 
        </p>
        <ul>
            <li>\(\mu\): media de la distribuci√≥n</li>
            <li>\(\sigma\): desviaci√≥n est√°ndar</li>
            <li>x: valor de la variable aleatoria</li>
            <li>e: base del logaritmo natural</li>
            <li>\(\pi\): constante pi</li>
        </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>An√°lisis de experimentos cient√≠ficos donde se espera que los datos se distribuyan sim√©tricamente alrededor de un valor central.</li>
        <li>Modelado de fen√≥menos naturales y sociales que presentan variabilidad aleatoria.</li>
        <li>Inferencia estad√≠stica: Estimaci√≥n de par√°metros poblacionales y realizaci√≥n de pruebas de hip√≥tesis.</li>
    </ul>
    <p><strong> Ejemplo:</strong> Medir la altura de 100 estudiantes y analizar si la distribuci√≥n de las alturas se ajusta a una distribuci√≥n normal.</p>
    <p>¬øCuando usar?</p>
   <p>Modelar datos continuos con una distribuci√≥n sim√©tricos</p>
    
   
   <h2>4.6 Distribuci√≥n T-student</h2>
    <p>La distribuci√≥n t-student es similar a la distribuci√≥n normal, pero se utiliza cuando el tama√±o de la muestra es peque√±o y la desviaci√≥n est√°ndar poblacional (œÉ) es desconocida. Se caracteriza por su grados de libertad (ŒΩ) y un par√°metro de ubicaci√≥n (Œº).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La forma de la distribuci√≥n depende de los grados de libertad (ŒΩ).</li>
        <li>Para grados de libertad altos, se aproxima a la distribuci√≥n normal.</li>
        <li>Se utiliza para realizar inferencia estad√≠stica cuando la œÉ es desconocida y el tama√±o de la muestra es peque√±o.</li>
    </ul>
    <p>Su formula es: <br>
        \( f(t) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu \pi} \Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}} \) <br>
        Donde: 
    </p>
    <ul>
        <li>t: valor de la variable aleatoria</li>
        <li>\(\nu\): grados de libertad</li>
        <li>\(\Gamma\): funci√≥n gamma</li>
        <li>\(\pi\): constante pi</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>An√°lisis de experimentos donde el tama√±o de la muestra es limitado.</li>
        <li>Estimaci√≥n de la media poblacional cuando la œÉ es desconocida.</li>
        <li>Realizaci√≥n de pruebas de hip√≥tesis sobre la media poblacional.</li>
    </ul>
    <p><strong>Ejemplo:</strong> Comparar la media de las calificaciones en matem√°ticas de dos grupos de estudiantes con tama√±os de muestra peque√±os.</p>
    <h2>4.7 Distribuci√≥n Chi cuadrada</h2>
    <p>La distribuci√≥n chi-cuadrada (œá¬≤) se utiliza para analizar la independencia entre dos variables categ√≥ricas. Se caracteriza por sus grados de libertad (ŒΩ).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La curva de densidad de probabilidad es asim√©trica a la derecha.</li>
        <li>No existe un valor m√°ximo para la distribuci√≥n.</li>
        <li>Se utiliza para realizar pruebas de hip√≥tesis sobre la independencia entre dos variables categ√≥ricas.</li>
    </ul>
    <p>Su formula es: <br>
        \( X = \sum_{i=1}^{k} Z_i^2 \) <br>
        Donde: 
    </p>
    <ul>
        <li>\(Z_i\): variables aleatorias normales est√°ndar</li>
        <li>k: grados de libertad</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>An√°lisis de tablas de contingencia para verificar si existe asociaci√≥n entre dos variables categ√≥ricas.</li>
        <li>Evaluaci√≥n de la bondad de ajuste de un modelo de distribuci√≥n de probabilidad a datos observados.</li>
        <li>Comparaci√≥n de varianzas poblacionales.</li>
    </ul>
    <p><strong>Ejemplo:</strong>Analizar si existe relaci√≥n entre el color de ojos y la preferencia por un tipo de m√∫sica en un grupo de personas.</p>
    <h2>4.8 Distribuci√≥n F</h2>
    <p>La distribuci√≥n F se utiliza para comparar dos varianzas poblacionales. Se caracteriza por sus dos grados de libertad (ŒΩ1 y ŒΩ2).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La curva de densidad de probabilidad es asim√©trica a la derecha.</li>
        <li>No existe un valor m√°ximo para la distribuci√≥n.</li>
        <li>Se utiliza para realizar pruebas de hip√≥tesis sobre la igualdad de varianzas poblacionales.</li>
    </ul>
    <p>Su formula es: <br>
        \( F = \frac{(U/d_1)}{(V/d_2)} \) <br>
        Donde: 
    </p>
    <ul>
        <li>U: variable aleatoria Chi-cuadrada con \( d_1 \) grados de libertad</li>
        <li>V: variable aleatoria Chi-cuadrada con \( d_2 \) grados de libertad</li>
        <li>d_1: grados de libertad del numerador</li>
        <li>d_2: grados de libertad del denominador</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>Comparaci√≥n de la variabilidad de dos grupos de datos.</li>
        <li>Evaluaci√≥n de la efectividad de un tratamiento experimental en comparaci√≥n con un grupo control.</li>
        <li>An√°lisis de experimentos de dise√±o factorial.</li>
    </ul>
    <p><strong>Ejemplo:</strong>Comparar la variabilidad en las calificaciones de matem√°ticas de dos grupos de estudiantes que recibieron diferentes m√©todos de ense√±anza.</p>
    
    <h3>Actividad Desarrollada</h3>
    <p>En este video exploramos una serie de distribuciones de probabilidad fundamentales en estad√≠stica, proporcionando una comprensi√≥n profunda de c√≥mo modelan diversos fen√≥menos y eventos aleatorios. </p>
    <a href="https://www.canva.com/design/DAGKDU7C93A/cOCIm7GjhGs4oAjW0SXwQA/view?utm_content=DAGKDU7C93A&utm_campaign=designshare&utm_medium=link&utm_source=recording_view " >Video de ejemplo sobre Distribuci√≥n binomial</a>
    
    <h1>5.1 Regresi√≥n y correlaci√≥n</h1>
    
    <h2>5.1.1 Diagrama de dispersi√≥n</h2>
    <p>Un diagrama de dispersi√≥n, tambi√©n conocido como gr√°fico de dispersi√≥n o gr√°fico de correlaci√≥n, es una representaci√≥n gr√°fica de dos variables para un conjunto de datos. En este gr√°fico, se ubican los puntos de datos en un plano cartesiano, donde cada punto representa el valor de una variable en el eje X y el valor de la otra variable en el eje Y</p>
    <p>El patr√≥n de los puntos en un diagrama de dispersi√≥n puede proporcionar informaci√≥n valiosa sobre la relaci√≥n entre las dos variables. Si los puntos est√°n distribuidos aleatoriamente sin una tendencia aparente, se puede inferir que no existe una relaci√≥n lineal entre las variables. Por otro lado, si los puntos tienden a seguir una l√≠nea recta o una curva, se puede inferir que existe una relaci√≥n lineal o curvil√≠nea entre las variables, respectivamente.</p>
    <h2>5.1.2 Regresi√≥n lineal simple</h2>
    <p>La regresi√≥n lineal simple es un m√©todo estad√≠stico para modelar la relaci√≥n entre una variable dependiente (Y) y una variable independiente (X) mediante una ecuaci√≥n lineal. La forma general de la ecuaci√≥n es:</p>
    <p>Y=Œ≤0 + Œ≤1 * X+œµ</p>
    <p>Donde:</p>
    <ul>
        <li>Y es la variable dependiente.</li>
        <li>X es la variable independiente.</li>
        <li>Œ≤0 y  Œ≤1 son los coeficientes de la regresi√≥n que se estiman a partir de los datos.</li>
        <li>œµ es el t√©rmino de error, que representa la variabilidad no explicada por la relaci√≥n lineal.</li>
    </ul>
    <h2>5.1.3 Correlaci√≥n</h2>
    <p>La correlaci√≥n es una medida de la fuerza y la direcci√≥n de la relaci√≥n entre dos variables. Se expresa mediante un coeficiente de correlaci√≥n, que puede tomar valores entre -1 y 1.</p>
    <ul>
        <li>Un coeficiente de correlaci√≥n de 0 indica que no existe correlaci√≥n entre las variables.</li>
        <li>Un coeficiente de correlaci√≥n positivo indica que las variables est√°n correlacionadas positivamente, es decir, que a medida que aumenta el valor de una variable, tambi√©n aumenta el valor de la otra variable.</li>
        <li>Un coeficiente de correlaci√≥n negativo indica que las variables est√°n correlacionadas negativamente, es decir, que a medida que aumenta el valor de una variable, disminuye el valor de la otra variable.</li>
    </ul>
    <h2>5.1.4 Determinaci√≥n y an√°lisis de los coeficientes de correlaci√≥n y de determinaci√≥n</h2>
    <p><strong>Coeficiente de correlaci√≥n  ùëü:</strong>  Calcula la intensidad y la direcci√≥n de la relaci√≥n entre dos variables. El coeficiente de correlaci√≥n, como se mencion√≥ anteriormente, mide la fuerza y la direcci√≥n de la relaci√≥n entre dos variables. Su interpretaci√≥n debe hacerse con cautela, ya que no implica necesariamente una relaci√≥n causal entre las variables.
 </p>
 <p><strong>Coeficiente de determinaci√≥n R ^ 2 : </strong> Indica la proporci√≥n de la varianza de la variable dependiente que es predecible a partir de la variable independiente. Se interpreta como el porcentaje de la variabilidad de  ùëå que es explicada por  ùëã.  El coeficiente de determinaci√≥n, tambi√©n conocido como R¬≤, indica la proporci√≥n de la variabilidad total de la variable dependiente que puede explicarse por la variable independiente. Se calcula como el cuadrado del coeficiente de correlaci√≥n. Un valor de R¬≤ cercano a 1 indica que la variable independiente explica una gran parte de la variabilidad de la variable dependiente, mientras que un valor cercano a 0 indica que la variable independiente explica una peque√±a parte de la variabilidad de la variable dependiente.
</p>
    <h2>5.1.5 Distribuci√≥n normal bidimensional</h2>
    <p>La distribuci√≥n normal bidimensional es una distribuci√≥n de probabilidad conjunta de dos variables aleatorias. Esta distribuci√≥n se caracteriza por tener una forma de campana en ambas dimensiones.</p>
    <p>En el contexto de la regresi√≥n lineal, la distribuci√≥n normal bidimensional es importante porque se asume que los errores aleatorios (Œµ) en la ecuaci√≥n de regresi√≥n siguen una distribuci√≥n normal bidimensional con media 0 y varianza constante.</p>
    <h2>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlaci√≥n</h2>
    <p>Para evaluar la significancia del coeficiente de correlaci√≥n  r:</p>
    <ul>
        <li>Intervalos de confianza: Los intervalos de confianza para el coeficiente de correlaci√≥n proporcionan un rango de valores dentro del cual es probable que se encuentre el valor verdadero de la poblaci√≥n. Se calculan utilizando la distribuci√≥n t de Student.</li>
        <li>Pruebas de hip√≥tesis: Las pruebas de hip√≥tesis se utilizan para determinar si el valor observado del coeficiente de correlaci√≥n es estad√≠sticamente significativo, es decir, si es diferente de 0. La prueba m√°s com√∫n para el coeficiente de correlaci√≥n es la prueba t de Student.</li>
    </ul>
    <h2>5.1.7 Errores de medici√≥n</h2>
    <p>Los errores de medici√≥n son discrepancias entre el valor medido de una variable y su valor verdadero. En el contexto de regresi√≥n y correlaci√≥n, los errores de medici√≥n pueden introducir sesgos y reducir la precisi√≥n de los resultados. Estrategias como la validaci√≥n cruzada y el an√°lisis de residuos ayudan a identificar y mitigar estos errores.</p>
   <p>Estos conceptos forman la base de la comprensi√≥n y el an√°lisis de la relaci√≥n entre variables cuantitativas en estad√≠stica, proporcionando herramientas para modelar y entender datos en diversos campos de estudio.</p> 
</body>
</html> 