<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Estadística descriptiva</title>
</head>
<body>
    <h1>1 Estadística descriptiva</h1>
   
    <h2>1.1 Conceptos basicos de estadistica</h2>
    <h3>Definición</h3>
    <p>La estadística es una ciencia que se encarga de la recolección, organización, análisis e interpretación de datos para obtener conclusiones sobre un conjunto de individuos o eventos. Se utiliza en diversos campos como la investigación científica, la economía, la medicina, la ingeniería y las ciencias sociales.</p>
    <h3>Teoría de decisión</h3>
    <p> La teoría de decisión es una rama de la estadística que se enfoca en tomar decisiones óptimas frente a la incertidumbre. Se utiliza para evaluar diferentes opciones y elegir la que tiene la mayor probabilidad de éxito, considerando los riesgos y beneficios asociados a cada una.</p>
    <h3>Población</h3>
    <p> La población es el conjunto completo de individuos o eventos que queremos estudiar. Es un grupo finito o infinito que tiene características comunes que nos interesan.</p>
    <h3>Muestra aleatoria</h3>
    <p>Una muestra aleatoria es un subconjunto de la población seleccionado de tal manera que cada individuo tiene la misma probabilidad de ser elegido. Se utiliza para obtener información sobre la población sin tener que estudiar a todos los individuos.</p>
    <h3>Parámetros aleatorios </h3>
    <p> Los parámetros aleatorios son características desconocidas de la población que se estiman a partir de una muestra. Se representan con letras griegas, como μ para la media y σ para la desviación estándar.</p>
    
    <h2>1.2 Descripción de datos</h2>
    <h3>Datos agrupados</h3>
    <p> Los datos agrupados son aquellos que se presentan en intervalos o clases. Se utilizan cuando se tienen muchos datos o cuando los datos no son precisos.</p>
    <h3>Datos no agrupados</h3>
    <p>Los datos no agrupados son aquellos que se presentan en su valor individual. Se utilizan cuando se tienen pocos datos o cuando los datos son precisos.</p>
    <h3>Frecuencia de clase</h3>
    <p>La frecuencia de clase es el número de individuos que caen en un intervalo o clase.</p>
    <h3>Frecuencia relativa</h3>
    <p> La frecuencia relativa es la proporción de individuos que caen en un intervalo o clase. Se calcula dividiendo la frecuencia de clase por el tamaño total de la muestra.</p>
    <h3>Punto medio </h3>
    <p>El punto medio es el valor promedio de un intervalo o clase. Se calcula sumando los límites inferior y superior del intervalo y dividiendo por dos.</p>
    <h3>Límites</h3>
    <p>Los límites son los valores que definen un intervalo o clase. El límite inferior es el valor más pequeño del intervalo, mientras que el límite superior es el valor más grande del intervalo.</p>
    
    <h2>1.3 Medidas de tendencia central</h2>
    <h3>Media aritmética</h3>
    <p>La media aritmética es la suma de todos los valores de una muestra dividida por el tamaño de la muestra. Se representa con la letra μ o X̅.</p>
    <h3>Media geométrica</h3>
    <p> La media geométrica es el n-ésimo raíz del producto de todos los valores de una muestra. Se representa con la letra G.</p>
    <h3>Media ponderada</h3>
    <p> La media ponderada es la suma de los productos de cada valor de una muestra por su peso correspondiente dividida por la suma de los pesos. Se utiliza cuando los datos tienen diferente importancia.</p>
    <h3>Mediana </h3>
    <p>La mediana es el valor que divide a la muestra ordenada en dos partes de igual tamaño. Se representa con la letra M. </p>
    <h3>Moda</h3>
    <p>La moda es el valor que aparece con mayor frecuencia en una muestra. Se representa con la letra Mo.</p>
    <h3>Medidas de dispersión </h3>
    <p> Las medidas de dispersión indican qué tan dispersos están los datos alrededor de la medida de tendencia central. Las medidas de dispersión más comunes son la varianza, la desviación estándar, la desviación media y la desviación mediana.</p>
    <h3>Varianza</h3>
    <p>La varianza es el promedio del cuadrado de las desviaciones de cada valor de la muestra respecto a la media. Se representa con la letra σ^2.</p>
    <h3>Desviación estándar</h3>
    <p> La desviación estándar es la raíz cuadrada de la varianza. Se representa con la letra σ.</p>
    <h3>Desviación media</h3>
    <p>La desviación media es el promedio de las distancias absolutas de cada valor de la muestra respecto a la media.</p>
    <h3>Desviación mediana </h3>
    <p> La desviación mediana es la mediana de las distancias absolutas de cada valor de la muestra respecto a la mediana.</p>
    <h3>Rango</h3>
    <p>El rango es la diferencia entre el valor máximo y el valor mínimo de una muestra.</p>
   
    <h2>1.4 Parámetros para datos agrupados</h2>
    <h3>Media muestral agrupada </h3>
    <p> La media muestral agrupada se calcula utilizando la siguiente fórmula:</p>
    <p>Media muestral agrupada = Σ(fi * xi) / Σfi</p>
    <p>Donde:</p>
    <ul>
        <li>fi es la frecuencia de la clase i</li>
        <li>xi es el punto medio de la clase i</li>
    </ul>
    <h3>Mediana muestral agrupada</h3>
    <p>La mediana muestral agrupada se calcula dividiendo la población en dos partes iguales y luego identificando la clase en la que cae la mediana. La mediana muestral agrupada se calcula utilizando la siguiente fórmula:</p>
   <p>Mediana muestral agrupada = límite inferior de la clase + (h(N/2 - Σfi) / fi)</p>
   <p>Donde:</p>
    <ul>
        <li>N es el total de elementos de la muestra.</li>
        <li>Σfi es la suma de las frecuencias acumuladas hasta la clase anterior a la que contiene la mediana.</li>
        <li>h es el ancho de la clase que contiene la mediana.</li>
        <li>fi es la frecuencia de la clase que contiene la mediana.</li>
    </ul> 
   <h3>Moda muestral agrupada </h3>
    <p>La moda muestral agrupada es la clase que tiene la mayor frecuencia.</p>
   
    <h2>1.5 Distribución de frecuencias</h2>
    <p>Una distribución de frecuencias es una tabla que muestra la distribución de los valores de un conjunto de datos en clases o intervalos. La distribución de frecuencias incluye la frecuencia de cada clase, la frecuencia relativa de cada clase y el porcentaje de cada clase.</p>
    <h3>Componentes de una distribución de frecuencias</h3>
    <ul>
        <li>Clases o intervalos: Son los grupos en los que se dividen los datos.</li>
        <li>Frecuencia de clase: Es el número de elementos que caen en cada clase o intervalo.</li>
        <li>Frecuencia relativa: Es la proporción de elementos que caen en cada clase o intervalo con respecto al total de elementos. Se calcula dividiendo la frecuencia de clase por el total de elementos.</li>
        <li>Porcentaje: Es la frecuencia relativa expresada en tanto por ciento. Se calcula multiplicando la frecuencia relativa por 100.</li>
    </ul>
    
    <h2>1.6 Técnicas de agrupación de datos</h2>
    <p>La agrupación de datos es el proceso de dividir un conjunto de datos en clases o intervalos. La elección del número y el ancho de las clases es importante para obtener una buena representación de los datos.</p>
    <h3>Factores a considerar al elegir el número y el ancho de las clases</h3>
    <ul>
        <li>El tamaño del conjunto de datos: Cuanto mayor sea el conjunto de datos, más clases se pueden utilizar.</li>
        <li>La variabilidad de los datos: Si los datos son muy variables, se necesitarán más clases para capturarlos adecuadamente.</li>
        <li>El propósito del análisis: El propósito del análisis también influirá en la elección del número y el ancho de las clases.</li>
    </ul>
    <h3>Métodos para agrupar datos</h3>
    <ul>
        <li>Agrupación por igual ancho: Este método consiste en dividir el rango de los datos en clases de igual ancho.</li>
        <li>Agrupación por frecuencias iguales: Este método consiste en dividir los datos en clases de tal manera que cada clase tenga aproximadamente el mismo número de elementos.</li>
        <li>Agrupación por percentiles: Este método consiste en dividir los datos en clases de tal manera que cada clase contenga un porcentaje específico de la población.</li>
    </ul>

    <h2>1.7 Técnicas de muestreo</h2>
    <p>El muestreo es el proceso de seleccionar un subconjunto de la población para estudiar las características de toda la población. El objetivo del muestreo es obtener una muestra representativa de la población, es decir, una muestra que refleje las características de la población en general.</p>
    <h3>Tipos de muestreo</h3>
    <ul>
        <li>Muestreo aleatorio simple: En este tipo de muestreo, cada elemento de la población tiene la misma probabilidad de ser seleccionado.</li>
        <li>Muestreo estratificado: En este tipo de muestreo, la población se divide en estratos o subgrupos, y luego se selecciona una muestra aleatoria de cada estrato.</li>
        <li>Muestreo sistemático: En este tipo de muestreo, se selecciona un elemento de la población como punto de partida, y luego se seleccionan otros elementos a intervalos regulares.</li>
        <li>Muestreo por conglomerados: En este tipo de muestreo, la población se divide en conglomerados o grupos, y luego se selecciona una muestra aleatoria de conglomerados.</li>
    </ul>
    <p>La elección del tipo de muestreo adecuado dependerá del tamaño y la estructura de la población, del propósito del estudio y de los recursos disponibles.</p>
    
    <h2>1.8 Histogramas</h2>
    <p>Un histograma es una representación gráfica de la distribución de frecuencias de un conjunto de datos. Se construye utilizando barras rectangulares, donde la altura de cada barra es proporcional a la frecuencia de la clase correspondiente. A continuación un ejemplo:</p>
    <center>
    <img  src="https://www.leadingedgegroup.com/wp-content/uploads/2017/11/histogram.jpg.webp" >
</center>
    <h3>Componentes de un histograma</h3>
    <ul>
        <li>Eje de abscisas: Representa las clases o intervalos de los datos.</li>
        <li>Eje de ordenadas: Representa la frecuencia o la frecuencia relativa de los datos.</li>
        <li>Barras rectangulares: Cada barra rectangular representa una clase o intervalo de los datos. La altura de la barra es proporcional a la frecuencia o la frecuencia relativa de la clase.</li>
      </ul>
      
    <h3>Pasos para construir un histograma</h3>
    <ol>
        <li>Determinar las clases o intervalos: El primer paso es determinar las clases o intervalos en que se van a agrupar los datos. La elección del número y el ancho de las clases es importante para obtener una buena representación de los datos.</li>
        <li>Calcular la frecuencia de cada clase: Una vez que se han determinado las clases, se calcula la frecuencia de cada clase. La frecuencia de clase es el número de elementos que caen en cada clase o intervalo.</li>
        <li>Dibujar el eje de abscisas: El eje de abscisas se dibuja en la parte inferior del gráfico. Se debe dividir en intervalos iguales que representen las clases o intervalos de los datos.</li>
        <li>Dibujar el eje de ordenadas: El eje de ordenadas se dibuja en el lado izquierdo del gráfico. Se debe escalar de acuerdo a la frecuencia o la frecuencia relativa de los datos.</li>
        <li>Dibujar las barras rectangulares: Se dibuja una barra rectangular para cada clase o intervalo. La altura de la barra debe ser proporcional a la frecuencia o la frecuencia relativa de la clase.</li>
        <li>Etiquetar el histograma: Se debe etiquetar el eje de abscisas con los nombres de las clases o intervalos, y el eje de ordenadas con la frecuencia o la frecuencia relativa. También se debe poner un título al histograma.</li>
      </ol>
      
    <h3>Interpretación de histogramas</h3>
    <p>Los histogramas se pueden utilizar para interpretar la distribución de los datos. Por ejemplo, un histograma simétrico indica que los datos están distribuidos uniformemente alrededor de la media. Un histograma asimétrico a la derecha indica que los datos están concentrados en la parte izquierda del gráfico, mientras que un histograma asimétrico a la izquierda indica que los datos están concentrados en la parte derecha del gráfico. Un histograma con dos o más picos indica que los datos son multimodales.</p>
    <p>Los histogramas son una herramienta útil para explorar y visualizar datos. Se pueden utilizar para identificar patrones, tendencias y anomalías en los datos.</p>






    <h1>2 Fundamentos de la Teoria de Probabilidad</h1>

    <h2>2.1 Técnicas de Conteo</h2>
    <p>Las técnicas de conteo son herramientas matemáticas que permiten determinar el número de resultados posibles en situaciones que involucran la elección o disposición de elementos. Estas técnicas son fundamentales en áreas como la probabilidad, la estadística y la combinatoria.</p>
    <h3>2.1.1 Principio aditivo</h3>
    <p>El principio aditivo establece que si hay n maneras de realizar una acción y m maneras de realizar otra acción, entonces hay n + m maneras de realizar ambas acciones de forma independiente. En otras palabras, si A y B son eventos disjuntos (no pueden ocurrir al mismo tiempo), entonces la probabilidad de que ocurra A o B es la suma de sus probabilidades individuales:</p>
    <p>P(A o B) = P(A) + P(B)    </p>
    <p>Ejemplo: Supongamos que una persona debe elegir entre dos restaurantes para cenar: un restaurante italiano y un restaurante chino. Si hay 5 opciones de platos en el restaurante italiano y 7 opciones de platos en el restaurante chino, ¿cuántas opciones de plato tiene la persona en total?</p>
    <p> Solución: Aplicando el principio aditivo, la persona tiene 5 + 7 = 12 opciones de plato en total.</p>
    <h3>2.1.2 Principio multiplicativo</h3>
    <p>El principio multiplicativo establece que si hay n maneras de realizar una acción y luego hay m maneras de realizar otra acción dependiente de la primera, entonces hay n * m maneras de realizar ambas acciones en conjunto. En otras palabras, si A y B son eventos dependientes (la ocurrencia de uno afecta la probabilidad del otro), entonces la probabilidad de que ocurran A y B es la probabilidad de A multiplicada por la probabilidad de B dado que A ya ha ocurrido:</p>
    <p>P(A y B) = P(A) * P(B | A)</p>
    <h3>2.1.3 Notación Factorial</h3>
    <p>La notación factorial se utiliza para representar el producto de una secuencia de números enteros positivos consecutivos. El factorial de n, que se denota como n!, se define como:</p>
    <p>n! = n * (n - 1) * (n - 2) * ... * 2 * 1</p>
    <p>Por ejemplo, 5! = 5 * 4 * 3 * 2 * 1 = 120.</p>
    <p>La notación factorial es especialmente útil en el contexto de las permutaciones y combinaciones.</p>
    <h3>2.1.4 Permutaciones</h3>
    <p>La permutación es una técnica de conteo que permite calcular las posibles ordenaciones de los elementos de un conjunto o número de elementos del espacio muestral de un experimento aleatorio. En esta técnica de conteo se considera que existe el orden en la muestra, pero no es posible repetir ningún elemento de la población en su conformación. Se puede calcular utilizando la siguiente fórmula:</p>
    <p>nPr=(n!)/(n-r)!</p>
    <h3>2.1.5 Combinaciones</h3>
    <p>Una combinación es una selección de k elementos de un conjunto de n elementos, sin importar el orden en que se seleccionen. El número de combinaciones de n elementos tomados de k en k se denota como nCk y se puede calcular utilizando la siguiente fórmula:</p>
    <p>nCk = n! / (k! * (n - k)!)</p>
    <h3>2.1.6 Diagrama de Árbol</h3>
    <p>Un diagrama de árbol es una herramienta visual que se utiliza para representar las diferentes posibilidades en situaciones que involucran decisiones sucesivas. Cada rama del árbol representa una elección, y las probabilidades se pueden asignar a cada rama.</p>
    <h3>2.1.7 Teorema del Binomio</h3>
    <p>El Teorema del Binomio, también conocido como Binomio de Newton, es una fórmula matemática que describe cómo se expande la potencia "n" de un binomio (una expresión con dos términos). La fórmula se expresa como:</p>
    <p>(a + b)^n = Σ(k=0; n) (nCk) * a^(n-k) * b^k</p>
    <p>Donde:</p>
    <ul>
        <li>(a + b)<sup>n</sup> representa el binomio "a + b" elevado a la potencia "n".</li>
        <li>Σ indica una sumatoria, lo que significa que la expresión representa la suma de todos los términos que se obtienen al expandir el binomio.</li>
        <li>(nCk) es el coeficiente binomial de "n" elegir "k", que se calcula como n! / (k! * (n-k)!). Este coeficiente determina el número de veces que aparece cada término en la expansión.</li>
        <li>a<sup>(n-k)</sup> representa "a" elevado a la potencia "n-k". Esta potencia indica la contribución de "a" en cada término de la expansión.</li>
        <li>b<sup>k</sup> representa "b" elevado a la potencia "k". Esta potencia indica la contribución de "b" en cada término de la expansión.</li>
      </ul>

    <h2>2.2 Teoría elemental de probabilidad</h2>
    <p>La teoría elemental de la probabilidad se basa en conceptos básicos para cuantificar la probabilidad de que ocurra un evento en un experimento aleatorio. Se define la probabilidad de un evento "A" como la razón entre el número de resultados favorables a "A" y el número total de resultados posibles en el espacio muestral. Matemáticamente, se expresa como:</p>
    <p>P(A) = n(A) / n(S)</p>
    <p>Donde:</p>
    <ul>
        <li>P(A) representa la probabilidad del evento "A".</li>
        <li>n(A) es el número de resultados favorables a "A".</li>>
        <li>n(S) es el número total de resultados posibles en el espacio muestral "S".</li>
      </ul>
    <h3>Propiedades básicas de la probabilidad:</h3>
    <ul>
          <li>0 ≤ P(A) ≤ 1: La probabilidad de cualquier evento debe estar entre 0 y 1. Un valor de 0 indica que el evento es imposible, mientras que 1 indica que es seguro que ocurra.</li>
          <li>P(S) = 1: La probabilidad del espacio muestral completo siempre es 1.</li>
          <li>Si A y B son eventos mutuamente excluyentes, entonces P(A ∪ B) = P(A) + P(B). Eventos mutuamente excluyentes son aquellos que no pueden ocurrir simultáneamente. La unión (∪) representa la probabilidad de que ocurra al menos uno de los eventos.</li>
          <li>Si A y B son eventos independientes, entonces P(A ∩ B) = P(A) * P(B). Eventos independientes son aquellos en los que la ocurrencia de uno no afecta la probabilidad del otro. La intersección (∩) representa la probabilidad de que ocurran ambos eventos simultáneamente.</li>
    </ul>
    <h2>2.3 Probabilidad de Eventos: Definición de espacio muestral, definición de evento, simbología, unión, intersección, diagramas de Venn.</h2>
    <h3>Definición de espacio muestral</h3>
    <p>El espacio muestral, denotado por Ω, es el conjunto que contiene todos los resultados posibles de un experimento aleatorio. En otras palabras, es la colección completa de todos los eventos que pueden ocurrir. Cada resultado en el espacio muestral se llama evento elemental.</p>
    <p>Ejemplo: Si lanzamos una moneda, el espacio muestral Ω sería {cara, cruz}.</p>
    <h3>Definición de evento</h3>
    <p>Un evento es un subconjunto del espacio muestral. Es un conjunto de resultados posibles que nos interesa considerar. Puede ser un solo resultado elemental o una combinación de ellos.</p>
    <p>Ejemplo: Si lanzamos una moneda, el evento "obtener cara" sería {cara}.</p>
    <h3>Simbología</h3>
    <ul>
        <li>Ω: Espacio muestral</li>
        <li>A: Evento</li>
        <li>A̅: Complemento de A (conjunto de resultados en Ω que no están en A)</li>
        <li>A ∪ B: Unión de A y B (conjunto de resultados que están en A o en B o en ambos)</li>
        <li>A ∩ B: Intersección de A y B (conjunto de resultados que están en A y en B)</li>
    </ul>
    <h3>Diagrama de Venn</h3>
    <p>Un diagrama de Venn es una representación gráfica de dos o más eventos. Los eventos se representan por círculos o regiones, y la superposición de las regiones indica la intersección de los eventos.</p>
    
    <h2>2.4 Probabilidad con Técnicas de Conteo: Axiomas, Teoremas</h2>
    <h3>Axiomas</h3>
    <p>Los axiomas de la probabilidad son principios básicos que definen las propiedades de la probabilidad. Los tres axiomas principales son:</p>
    <ul>
        <li>No negatividad: P(A) ≥ 0 para todo evento A.        </li>
        <li>Certeza: P(Ω) = 1.        </li>
        <li>Ley de la aditividad: Si A y B son eventos mutuamente excluyentes (no tienen resultados en común), entonces P(A ∪ B) = P(A) + P(B).</li>
    </ul>
    <h3>Teoremas</h3>
    <p>Existen varios teoremas importantes en probabilidad con técnicas de conteo, como:</p>
    <ul>
        <li>Teorema de la multiplicación: Si un experimento se compone de n pasos sucesivos e independientes, la probabilidad de un resultado específico es el producto de las probabilidades de cada paso individual.</li>
        <li>Permutaciones: El número de formas de ordenar n objetos distintos es n!.        </li>
        <li>El número de formas de seleccionar k objetos de un conjunto de n objetos distintos sin importar el orden es nCk = n! / (k!(n - k)!).</li>
    </ul>
    
    <h2>2.5 Probabilidad condicional: Dependiente, Independiente</h2>
    <h3>Dependiente</h3>
    <p>Dos eventos A y B se consideran dependientes si la probabilidad de uno afecta la probabilidad del otro. En otras palabras, si saber que ha ocurrido A cambia la probabilidad de que ocurra B.

        Ejemplo: Sacar dos cartas de una baraja sin reponer. La probabilidad de sacar un rey en la segunda carta depende de si el rey se sacó en la primera carta.</p>
    
    <h3>Independiente</h3>
    <p>Dos eventos A y B se consideran independientes si la probabilidad de uno no afecta la probabilidad del otro. En otras palabras, saber que ha ocurrido A no cambia la probabilidad de que ocurra B.

        Ejemplo: Lanzar dos monedas. La probabilidad de obtener cara en la segunda moneda es la misma independientemente de si se obtuvo cara o cruz en la primera moneda.</p>
   
    <h2>2.6 Ley multiplicativa</h2>
    <p>La ley multiplicativa establece que la probabilidad de que ocurran dos eventos independientes A y B es el producto de sus probabilidades individuales:    </p>
    <p>P(A ∩ B) = P(A) * P(B)    </p>

    <h2>2.7 Eventos independientes: Regla de Bayes</h2>
    <p>La regla de Bayes es un teorema que permite calcular la probabilidad condicional de un evento A sabiendo que ha ocurrido otro evento B, cuando los eventos son independientes. Se expresa como:</p>
    <p>P(A | B) = (P(B | A) * P(A)) / P(B)</p>
    <ul>
        <li>P(B | A) es la probabilidad condicional de B dado A, es decir, la probabilidad de que ocurra B sabiendo que ya ha ocurrido A.</li>
        <li>P(B) es la probabilidad marginal de B, es decir, la probabilidad de que ocurra B sin tener en cuenta si ha ocurrido A o no.</li>
    </ul>
    
    
    
    
    <h1>3 Variables Aleatorias</h1>
    <h2>3.1 Variables aleatorias discretas</h2>
    <p>Las variables aleatorias discretas son aquellas en que el número de valores posibles que toman es finito o infinito, pero que puede numerarse</p>
    <h3>3.1.1 Distribución de probabilidad en forma general</h3>
    <p>Una variable aleatoria discreta X se define por su función de probabilidad, P(x), que asigna a cada valor posible x de X una probabilidad P(x)≥0, de tal manera que ∑ x∈X P(x)=1, donde X es el conjunto de valores posibles de X.</p>
    <p>La función de probabilidad P(x) puede representarse mediante una tabla de frecuencias o una gráfica de barras.</p>
    <h3>3.1.2 Valor esperado</h3>
    <p>La media o valor esperado es una medida de localización central de la variable aleatoria. Se calcula de la manera siguiente:</p>
    <img src="valorEsperado.png" class="imagenesFormulas">
    <p>es decir, es un promedio ponderado de los valores que toma la variable aleatoria (Xi ), donde las ponderaciones (o pesos) son las probabilidades [P(Xi )].</p>
    <h3>3.1.3 Variancia, desviación estándar</h3>
    <p>La varianza y la desviación estándar son medidas de dispersión o variabilidad de la variable aleatoria. La primera se calcula de la siguiente manera:</p>
    <img src="varianza.png" class="imagenesFormulas">
    <p>En otras palabras, es el promedio ponderado de las distancias al cuadrado de cada valor de la variable aleatoria respecto a su media. Esto indica cuán alejados están los valores en relación con la media. Se eleva al cuadrado para hacer más evidente esa distancia (variabilidad). También puede calcularse así:</p>
    <img src="varianza2.png" class="imagenesFormulas">
    <p>Como el resultado de la varianza se expresa en unidades al cuadrado, determinamos la desviación estándar calculando sólo la raíz cuadrada de la varianza.</p>
    <h3>3.1.4 Función acumulada</h3>
    <p>a función acumulada de una variable aleatoria discreta representa la probabilidad de que la variable tome un valor menor o igual a un valor específico x. Se define como:</p>
    <img src="funcionAcumulada.png" class="imagenesFormulas">
    <p>La función acumulada es una función no decreciente que va de 0 a 1.    </p>


    <h2>3.2 Variables aleatorias Continuas</h2>
    <p> En estadística, una variable aleatoria continua es aquella que puede tomar infinitos valores dentro de un intervalo real. A diferencia de las variables aleatorias discretas, que solo pueden tomar valores específicos, las variables continuas pueden tomar cualquier valor dentro de un rango definido</p>
    <h3>3.2.1 Distribución de probabilidad en forma general</h3>
    <p>Las variables aleatorias continuas se caracterizan por tener un conjunto infinito no numerable de valores posibles dentro de un intervalo. Su distribución de probabilidad se define mediante una función de densidad de probabilidad, f(x), que asigna a cada valor x en el intervalo de valores posibles X una densidad de probabilidad f(x)≥0, cumpliendo la condición de que la integral de la densidad de probabilidad en todo el intervalo sea igual a 1:</p>
    <img src="DitricucionDeProbabilidad.png" class="imagenesFormulas">
    <h3>3.2.2 Valor esperado</h3>
    <p>Es una medida de localización central de la variable aleatoria. Se calcula de la forma siguiente:</p>
    <img src="valorEsperadoContinuas.png" class="imagenesFormulas">
    <h3>3.2.3 Variancia, desviación estándar</h3>
    <p>Son medidas de dispersión o variabilidad de la variable aleatoria. Se calculan de esta  manera:</p>
    <img src="varianzaContinuas.png" class="imagenesFormulas">
    <p>Cabe recordar que la varianza también puede calcularse así:</p>
    <img src="varianza continuas2.png" class="imagenesFormulas">
    <p>De este modo determinamos la desviación estándar calculando únicamente la raíz cuadrada de la varianza.</p>
    <h3>3.2.4 Función acumulada</h3>
    <p>La función acumulada de una variable aleatoria continua representa la probabilidad de que la variable tome un valor menor o igual a un valor específico x. Se define como:</p>
    <img src="funcionAcumuladaContinuas.png" class="imagenesFormulas">
    <p>La función acumulada es una función no decreciente que va de 0 a 1.</p>
    <h3>3.2.5 Cálculos de probabilidad</h3>
    <p>Para calcular probabilidades relacionadas con una variable aleatoria continua, se utiliza la función acumulada. Por ejemplo, para calcular la probabilidad de que la variable aleatoria X tome un valor entre a y b, se utiliza la siguiente fórmula:</p>
    <img src="CalculosDeProb.png" class="imagenesFormulas">





    <h1>4 Distribuciones de Probabilidad</h1>
    <p>En el ámbito de la probabilidad y la estadística, las distribuciones de probabilidad desempeñan un papel fundamental para modelar el comportamiento de variables aleatorias en diversos contextos. Estas distribuciones permiten cuantificar la probabilidad de que una variable aleatoria tome un valor específico o se encuentre dentro de un intervalo particular. A continuación, se presenta una descripción más detallada de algunas de las distribuciones de probabilidad más comunes, adoptando un estilo técnico y formal:</p>
    <h2>4.1 Función de probabilidad </h2>
    <p>La función de probabilidad es una función matemática que asigna a cada valor posible de una variable aleatoria X su probabilidad de ocurrencia. Se representa con la notación P(X = x) o f(x) para una variable discreta, y con F(x) para una variable continua. La función de probabilidad debe cumplir las siguientes propiedades:</p>
    <ul>
        <li>P(X ≤ a) ≤ 1 para todo valor real a.</li>
        <li>Si X es discreta, entonces P(X = x) ≥ 0 para todo valor posible de x.</li>
        <li>Si X es continua, entonces F(x) es no decreciente y F(a) = 0 para todo a < mínimo valor posible de X.</li>
        <li>Si X es continua, entonces F(b) = 1 para todo b > máximo valor posible de X.</li>
    </ul>
    <p>La función de probabilidad es fundamental para calcular probabilidades de eventos relacionados con la variable aleatoria X.</p>
    <h2>4.2 Distribución binomial</h2>
    <p>La distribución binomial describe la probabilidad de obtener un número específico de "éxitos" en n experimentos independientes, donde cada experimento tiene la misma probabilidad de éxito p. Se utiliza cuando:</p>
    <ul>
        <li>La variable aleatoria X representa el número de éxitos.</li>
        <li>X es discreta con valores posibles 0, 1, 2, ..., n.</li>
        <li>Los experimentos son independientes.</li>
        <li>La probabilidad de éxito en cada experimento es la misma (p).</li>
    </ul>
    <p>La función de probabilidad de la distribución binomial para X = k éxitos en n experimentos es:</p>
    <p>P(X = k) = nCk * p^k * (1-p)^(n-k)</p>
    <p>Donde:</p><ul>
        <li>nCk es el número de combinaciones de n elementos tomados de k en k.</li>
        <li>p es la probabilidad de éxito en cada experimento.</li>
        <li>(1-p) es la probabilidad de fracaso en cada experimento.</li>
    </ul>
    <h2>4.3 Distribución hipergeométrica</h2>
    <p>La distribución hipergeométrica describe la probabilidad de obtener un número específico de "éxitos" en n experimentos sin reemplazo, donde la población inicial tiene N elementos, de los cuales K son éxitos. Se utiliza cuando:</p>
    <ul>
        <li>La variable aleatoria X representa el número de éxitos en la muestra.</li>
        <li>X es discreta con valores posibles 0, 1, 2, ..., min(n, K).</li>
        <li>Los experimentos son sin reemplazo.</li>
        <li>La población inicial es finita y conocida (N elementos).</li>
        <li>La probabilidad de éxito en cada experimento no es constante (depende del número de éxitos restantes en la población).</li>
    </ul>
    <p>La función de probabilidad de la distribución hipergeométrica para X = k éxitos en una muestra de n elementos es:</p>
    <p>P(X = k) = (K choose k) * (N-K choose n-k) / (N choose n)</p>
    <ul>
        <li>(K choose k) es el número de combinaciones de K elementos tomados de k en k.</li>
        <li>(N-K choose n-k) es el número de combinaciones de N-K elementos tomados de n-k en n-k.</li>
        <li>(N choose n) es el número de combinaciones de N elementos tomados de n en n.</li>
    </ul>
    <h2>4.4 Distribución de Poisson</h2>
    <p>La distribución de Poisson describe la probabilidad de observar un número específico de eventos en un intervalo de tiempo fijo, suponiendo que los eventos ocurren de forma independiente y con una tasa constante. Se utiliza cuando:</p>
    <ul>
        <li>La variable aleatoria X representa el número de eventos en un intervalo de tiempo fijo.</li>
        <li>X es discreta con valores posibles 0, 1, 2, ...</li>
        <li>Los eventos ocurren de forma independiente.</li>
        <li>La tasa de eventos (λ) es constante en el intervalo de tiempo.</li>
    </ul>
    <p>La función de probabilidad de la distribución de Poisson para X = k eventos en un intervalo de tiempo con tasa λ es:</p>
    <p>P(X = k) = (e^(-λ) * λ^k) / k!</p>
    <ul>
        <li>e es la base del logaritmo natural (aproximadamente 2.718).</li>
        <li>λ es la tasa de eventos en el intervalo de tiempo.</li>
        <li>k! es el factorial de k (k * (k-1) * (k-2) * ... * 1).</li>
    </ul>
    <h2>4.5 Distribución normal</h2>
    <p>La distribución normal, también conocida como distribución gaussiana, describe la probabilidad de que una variable aleatoria continua X tome un valor dentro de un intervalo específico. Se caracteriza por su media (μ) y su desviación estándar (σ).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La curva de densidad de probabilidad es simétrica alrededor de la media (μ).</li>
        <li>El 68% de los datos se encuentran dentro de un intervalo de 1 desviación estándar (μ ± σ) de la media.</li>
        <li>El 95% de los datos se encuentran dentro de un intervalo de 2 desviaciones estándar (μ ± 2σ) de la media.</li>
        <li>El 99.7% de los datos se encuentran dentro de un intervalo de 3 desviaciones estándar (μ ± 3σ) de la media.</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>Análisis de experimentos científicos donde se espera que los datos se distribuyan simétricamente alrededor de un valor central.</li>
        <li>Modelado de fenómenos naturales y sociales que presentan variabilidad aleatoria.</li>
        <li>Inferencia estadística: Estimación de parámetros poblacionales y realización de pruebas de hipótesis.</li>
    </ul>
    <p><strong> Ejemplo:</strong> Medir la altura de 100 estudiantes y analizar si la distribución de las alturas se ajusta a una distribución normal.</p>
    <h2>4.6 Distribución T-student</h2>
    <p>La distribución t-student es similar a la distribución normal, pero se utiliza cuando el tamaño de la muestra es pequeño y la desviación estándar poblacional (σ) es desconocida. Se caracteriza por su grados de libertad (ν) y un parámetro de ubicación (μ).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La forma de la distribución depende de los grados de libertad (ν).</li>
        <li>Para grados de libertad altos, se aproxima a la distribución normal.</li>
        <li>Se utiliza para realizar inferencia estadística cuando la σ es desconocida y el tamaño de la muestra es pequeño.</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>Análisis de experimentos donde el tamaño de la muestra es limitado.</li>
        <li>Estimación de la media poblacional cuando la σ es desconocida.</li>
        <li>Realización de pruebas de hipótesis sobre la media poblacional.</li>
    </ul>
    <p><strong>Ejemplo:</strong> Comparar la media de las calificaciones en matemáticas de dos grupos de estudiantes con tamaños de muestra pequeños.</p>
    <h2>4.7 Distribución Chi cuadrada</h2>
    <p>La distribución chi-cuadrada (χ²) se utiliza para analizar la independencia entre dos variables categóricas. Se caracteriza por sus grados de libertad (ν).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La curva de densidad de probabilidad es asimétrica a la derecha.</li>
        <li>No existe un valor máximo para la distribución.</li>
        <li>Se utiliza para realizar pruebas de hipótesis sobre la independencia entre dos variables categóricas.</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>Análisis de tablas de contingencia para verificar si existe asociación entre dos variables categóricas.</li>
        <li>Evaluación de la bondad de ajuste de un modelo de distribución de probabilidad a datos observados.</li>
        <li>Comparación de varianzas poblacionales.</li>
    </ul>
    <p><strong>Ejemplo:</strong>Analizar si existe relación entre el color de ojos y la preferencia por un tipo de música en un grupo de personas.</p>
    <h2>4.8 Distribución F</h2>
    <p>La distribución F se utiliza para comparar dos varianzas poblacionales. Se caracteriza por sus dos grados de libertad (ν1 y ν2).</p>
    <p>Propiedades:</p>
    <ul>
        <li>La curva de densidad de probabilidad es asimétrica a la derecha.</li>
        <li>No existe un valor máximo para la distribución.</li>
        <li>Se utiliza para realizar pruebas de hipótesis sobre la igualdad de varianzas poblacionales.</li>
    </ul>
    <p>Aplicaciones:</p>
    <ul>
        <li>Comparación de la variabilidad de dos grupos de datos.</li>
        <li>Evaluación de la efectividad de un tratamiento experimental en comparación con un grupo control.</li>
        <li>Análisis de experimentos de diseño factorial.</li>
    </ul>
    <p><strong>Ejemplo:</strong>Comparar la variabilidad en las calificaciones de matemáticas de dos grupos de estudiantes que recibieron diferentes métodos de enseñanza.</p>

</body>
</html> 